{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /usr/lib/python3.8/site-packages (4.1.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/lib/python3.8/site-packages (from transformers) (4.54.1)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/lib/python3.8/site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: sacremoses in /usr/lib/python3.8/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /usr/lib/python3.8/site-packages (from transformers) (0.9.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/lib/python3/dist-packages (from packaging->transformers) (2.4.6)\n",
      "Requirement already satisfied: joblib in /usr/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.0)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras_tuner in ./.local/lib/python3.8/site-packages (1.4.6)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3.8/site-packages (from keras_tuner) (20.9)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (2.6.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from keras_tuner) (2.22.0)\n",
      "Requirement already satisfied: kt-legacy in ./.local/lib/python3.8/site-packages (from keras_tuner) (1.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/lib/python3/dist-packages (from packaging->keras_tuner) (2.4.6)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers\n",
    "! pip install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Bidirectional, Dropout, GlobalMaxPool1D, concatenate, BatchNormalization\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_tuner.tuners import GridSearch\n",
    "from keras_tuner import HyperModel, Objective\n",
    "from keras import regularizers\n",
    "from decimal import Decimal\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"GPUs available: \", gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "if gpus:\n",
    "    # Assuming you want to use the first GPU if available\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        print(\"Using GPU: \", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth enabled\n"
     ]
    }
   ],
   "source": [
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alberto chosen\n",
      "290\n"
     ]
    }
   ],
   "source": [
    "choice = 'alberto' #umberto\n",
    "max_length = 0\n",
    "if choice == 'alberto':\n",
    "    training_data = pd.read_csv('archive/alberto_preprocessing_training_textual_haspeede2.csv')\n",
    "    test_data = pd.read_csv('archive/alberto_preprocessing/alberto_preprocessing_test_textual.csv')\n",
    "    max_length = 290\n",
    "    print('alberto chosen')\n",
    "else:\n",
    "    training_data = pd.read_csv('archive/umberto_preprocessing_training_textual_haspeede2.csv')\n",
    "    test_data = pd.read_csv('archive/umberto_preprocessing/umberto_preprocessing_test_textual.csv')\n",
    "    max_length = 357\n",
    "    print('umberto chosen')\n",
    "\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_politics = test_data[test_data['dataset']=='test_politics']\n",
    "test_data_religious = test_data[test_data['dataset']=='test_religious']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anonymized_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;user&gt; con tutte le denunce che si sta beccand...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;hashtag&gt; prescrizione &lt;/hashtag&gt; i t re magi ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>il &lt;hashtag&gt; movimento cinque stelle &lt;/hashtag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>la &lt;hashtag&gt; lega &lt;/hashtag&gt; e il &lt;hashtag&gt; mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>che cosa cambia questa &lt;hashtag&gt; legge &lt;/hasht...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12432</th>\n",
       "      <td>gli stati nazionali devono essere pronti a rin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12433</th>\n",
       "      <td>il ministro dell interno della germania &lt;hasht...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12434</th>\n",
       "      <td>&lt;hashtag&gt; salvini &lt;/hashtag&gt; in italia troppi ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12435</th>\n",
       "      <td>&lt;user&gt; &lt;user&gt; chi giubila in buona fede non ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12436</th>\n",
       "      <td>i giovani cristiani in &lt;hashtag&gt; etiopia &lt;/has...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12437 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         anonymized_text  label\n",
       "0      <user> con tutte le denunce che si sta beccand...      1\n",
       "1      <hashtag> prescrizione </hashtag> i t re magi ...      0\n",
       "2      il <hashtag> movimento cinque stelle </hashtag...      1\n",
       "3      la <hashtag> lega </hashtag> e il <hashtag> mo...      0\n",
       "4      che cosa cambia questa <hashtag> legge </hasht...      0\n",
       "...                                                  ...    ...\n",
       "12432  gli stati nazionali devono essere pronti a rin...      0\n",
       "12433  il ministro dell interno della germania <hasht...      0\n",
       "12434  <hashtag> salvini </hashtag> in italia troppi ...      0\n",
       "12435  <user> <user> chi giubila in buona fede non ha...      0\n",
       "12436  i giovani cristiani in <hashtag> etiopia </has...      0\n",
       "\n",
       "[12437 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anonymized_tweet_id</th>\n",
       "      <th>anonymized_text</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>424801448454884</td>\n",
       "      <td>questo anno &lt;hashtag&gt; babbo natale &lt;/hashtag&gt; ...</td>\n",
       "      <td>1</td>\n",
       "      <td>test_politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>775194088981616</td>\n",
       "      <td>adesso che in mezzo alla strada grazie al verg...</td>\n",
       "      <td>1</td>\n",
       "      <td>test_politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>386928936347190</td>\n",
       "      <td>circondatevi di persone che non sono diventate...</td>\n",
       "      <td>0</td>\n",
       "      <td>test_politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>957546674360002</td>\n",
       "      <td>seriamente per capire se un ladro mi entra in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>test_politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>530526299555950</td>\n",
       "      <td>che poi è probabile che &lt;hashtag&gt; spataro &lt;/ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>test_politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>791719192220932</td>\n",
       "      <td>&lt;user&gt; sono assuefatti non se ne rendono nemme...</td>\n",
       "      <td>1</td>\n",
       "      <td>test_politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>39222631664617</td>\n",
       "      <td>&lt;user&gt; io rimango basita dalla scaltrezza e sf...</td>\n",
       "      <td>1</td>\n",
       "      <td>test_politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>468315837641713</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; non sono scemi loro sono scemi q...</td>\n",
       "      <td>1</td>\n",
       "      <td>test_politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>25360395404144</td>\n",
       "      <td>&lt;hashtag&gt; sondaggio polito co &lt;/hashtag&gt; &lt;hash...</td>\n",
       "      <td>0</td>\n",
       "      <td>test_politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>834806744745258</td>\n",
       "      <td>viviamo in un mondo dove è necessario scrivere...</td>\n",
       "      <td>0</td>\n",
       "      <td>test_politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anonymized_tweet_id                                    anonymized_text  \\\n",
       "0         424801448454884  questo anno <hashtag> babbo natale </hashtag> ...   \n",
       "1         775194088981616  adesso che in mezzo alla strada grazie al verg...   \n",
       "2         386928936347190  circondatevi di persone che non sono diventate...   \n",
       "3         957546674360002  seriamente per capire se un ladro mi entra in ...   \n",
       "4         530526299555950  che poi è probabile che <hashtag> spataro </ha...   \n",
       "...                   ...                                                ...   \n",
       "3219      791719192220932  <user> sono assuefatti non se ne rendono nemme...   \n",
       "3220       39222631664617  <user> io rimango basita dalla scaltrezza e sf...   \n",
       "3221      468315837641713  <user> <user> non sono scemi loro sono scemi q...   \n",
       "3308       25360395404144  <hashtag> sondaggio polito co </hashtag> <hash...   \n",
       "3826      834806744745258  viviamo in un mondo dove è necessario scrivere...   \n",
       "\n",
       "      label        dataset  \n",
       "0         1  test_politics  \n",
       "1         1  test_politics  \n",
       "2         0  test_politics  \n",
       "3         0  test_politics  \n",
       "4         0  test_politics  \n",
       "...     ...            ...  \n",
       "3219      1  test_politics  \n",
       "3220      1  test_politics  \n",
       "3221      1  test_politics  \n",
       "3308      0  test_politics  \n",
       "3826      0  test_politics  \n",
       "\n",
       "[1400 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anonymized_tweet_id</th>\n",
       "      <th>anonymized_text</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>379748472796095</td>\n",
       "      <td>voglio abituare tutti gli abitanti del luogo e...</td>\n",
       "      <td>0</td>\n",
       "      <td>test_religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>195027074607893</td>\n",
       "      <td>l europa laica e comunista esce allo scoperto ...</td>\n",
       "      <td>0</td>\n",
       "      <td>test_religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>97213378242080</td>\n",
       "      <td>&lt;user&gt; gli ebrei insieme ai liberali e altre c...</td>\n",
       "      <td>0</td>\n",
       "      <td>test_religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>894894959501945</td>\n",
       "      <td>&lt;user&gt; la mussulmana lombarda per portarla a c...</td>\n",
       "      <td>1</td>\n",
       "      <td>test_religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>439618972593653</td>\n",
       "      <td>denunciare coloro che vogliono limitare le lib...</td>\n",
       "      <td>0</td>\n",
       "      <td>test_religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4395</th>\n",
       "      <td>391599381944152</td>\n",
       "      <td>&lt;user&gt; esatto brava ti dico di piu i nazisti n...</td>\n",
       "      <td>0</td>\n",
       "      <td>test_religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>974317501584882</td>\n",
       "      <td>&lt;user&gt; togliere la parola non vaccinati e mett...</td>\n",
       "      <td>0</td>\n",
       "      <td>test_religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>739414582677163</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; lo sai o no che i musulmani rico...</td>\n",
       "      <td>0</td>\n",
       "      <td>test_religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>470933865054049</td>\n",
       "      <td>berlino memoriale per gli ebrei assassinati d ...</td>\n",
       "      <td>0</td>\n",
       "      <td>test_religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>692345319594122</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; solo un terone dal culetto oliva...</td>\n",
       "      <td>0</td>\n",
       "      <td>test_religious</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anonymized_tweet_id                                    anonymized_text  \\\n",
       "605       379748472796095  voglio abituare tutti gli abitanti del luogo e...   \n",
       "606       195027074607893  l europa laica e comunista esce allo scoperto ...   \n",
       "607        97213378242080  <user> gli ebrei insieme ai liberali e altre c...   \n",
       "608       894894959501945  <user> la mussulmana lombarda per portarla a c...   \n",
       "609       439618972593653  denunciare coloro che vogliono limitare le lib...   \n",
       "...                   ...                                                ...   \n",
       "4395      391599381944152  <user> esatto brava ti dico di piu i nazisti n...   \n",
       "4396      974317501584882  <user> togliere la parola non vaccinati e mett...   \n",
       "4397      739414582677163  <user> <user> lo sai o no che i musulmani rico...   \n",
       "4398      470933865054049  berlino memoriale per gli ebrei assassinati d ...   \n",
       "4399      692345319594122  <user> <user> solo un terone dal culetto oliva...   \n",
       "\n",
       "      label         dataset  \n",
       "605       0  test_religious  \n",
       "606       0  test_religious  \n",
       "607       0  test_religious  \n",
       "608       1  test_religious  \n",
       "609       0  test_religious  \n",
       "...     ...             ...  \n",
       "4395      0  test_religious  \n",
       "4396      0  test_religious  \n",
       "4397      0  test_religious  \n",
       "4398      0  test_religious  \n",
       "4399      0  test_religious  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_religious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\")  #Musixmatch/umberto-commoncrawl-cased-v1\n",
    "\n",
    "def tokenize_function(sentence):\n",
    "    tokens = tokenizer.encode_plus(sentence, max_length=max_length,\n",
    "                                   truncation=True, padding='max_length',\n",
    "                                   add_special_tokens=True, return_attention_mask=True,\n",
    "                                   return_token_type_ids=False, return_tensors='tf')\n",
    "    return tokens['input_ids'], tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split + Tweets transformation for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = training_data['label']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(training_data, labels, test_size=0.20, random_state=SEED, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize two arrays for input tensors\n",
    "Xids = np.zeros((len(X_train['anonymized_text']), max_length))\n",
    "Xmask = np.zeros((len(X_train['anonymized_text']), max_length))\n",
    "\n",
    "for i, sentence in enumerate(X_train['anonymized_text']):\n",
    "    Xids[i, :], Xmask[i, :] = tokenize_function(sentence)\n",
    "    \n",
    "labels = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128  # we will use batches of 128\n",
    "\n",
    "# load arrays into tensorflow dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))\n",
    "\n",
    "# create a mapping function that we use to restructure our dataset\n",
    "def map_func(input_ids, masks, labels):\n",
    "    return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
    "\n",
    "# using map method to apply map_func to dataset\n",
    "dataset = dataset.map(map_func)\n",
    "\n",
    "# batch data\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "train=dataset\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "XidsVal = np.zeros((len(X_val['anonymized_text']), max_length))\n",
    "XmaskVal = np.zeros((len(X_val['anonymized_text']), max_length))\n",
    "\n",
    "for i, sentence in enumerate(X_val['anonymized_text']):\n",
    "    XidsVal[i, :], XmaskVal[i, :] = tokenize_function(sentence)\n",
    "    \n",
    "labels_val = y_val\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((XidsVal, XmaskVal, labels_val))\n",
    "dataset = dataset.map(map_func)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "validation = dataset\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "XidsTestPolitics = np.zeros((len(test_data_politics['anonymized_text']), max_length))\n",
    "XmaskTestPolitics = np.zeros((len(test_data_politics['anonymized_text']), max_length))\n",
    "\n",
    "for i, sentence in enumerate(test_data_politics['anonymized_text']):\n",
    "    XidsTestPolitics[i, :], XmaskTestPolitics[i, :] = tokenize_function(sentence)\n",
    "    \n",
    "labelsTPolitics = test_data_politics['label']\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((XidsTestPolitics, XmaskTestPolitics, labelsTPolitics))\n",
    "dataset = dataset.map(map_func)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "test_politics = dataset\n",
    "\n",
    "del dataset  # delete dataset to free up disk-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "XidsTestReligious = np.zeros((len(test_data_religious['anonymized_text']), max_length))\n",
    "XmaskTestReligious = np.zeros((len(test_data_religious['anonymized_text']), max_length))\n",
    "\n",
    "for i, sentence in enumerate(test_data_religious['anonymized_text']):\n",
    "    XidsTestReligious[i, :], XmaskTestReligious[i, :] = tokenize_function(sentence)\n",
    "    \n",
    "labelsTReligious = test_data_religious['label']\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((XidsTestReligious, XmaskTestReligious, labelsTReligious))\n",
    "dataset = dataset.map(map_func)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "test_religious = dataset\n",
    "\n",
    "del dataset  # delete dataset to free up disk-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = Precision()\n",
    "        self.recall = Recall()\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "    def result(self):\n",
    "        p = self.precision.result()\n",
    "        r = self.recall.result()\n",
    "        return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel\n",
    "embed_dim = 768  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "class MyHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = TFAutoModel.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\", from_pt=True) #Musixmatch/umberto-commoncrawl-cased-v1\n",
    "\n",
    "        input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
    "        mask = Input(shape=(max_length,), name='attention_mask', dtype='int32')\n",
    "\n",
    "        # we consume the last_hidden_state tensor from bert (discarding pooled_outputs)\n",
    "        embeddings = model(input_ids, attention_mask=mask)[0]\n",
    "\n",
    "        #X = TransformerBlock(embed_dim=embed_dim,num_heads=num_heads, ff_dim=ff_dim)(embeddings)\n",
    "        X = (LSTM(units=hp.Choice('LSTM_units', values=[64, 128]), recurrent_dropout=hp.Choice('LSTM_recurrent_dropout', values=[0.0,0.3]), return_sequences= True))(embeddings) \n",
    "        X = GlobalMaxPool1D()(X)\n",
    "        X = Dropout(rate=hp.Choice('rate_dropout', values=[0.6, 0.7]))(X)\n",
    "        \n",
    "        X = Dense(units=hp.Choice('dense_units', values=[16,32,64]),kernel_regularizer=regularizers.L2(hp.Choice('reg_value', [0.0,0.001])), activation=\"relu\")(X)\n",
    "        y = Dense(1, activation='sigmoid', name='outputs')(X)\n",
    "\n",
    "        # define input and output layers of our model\n",
    "        best_model = Model(inputs=[input_ids, mask], outputs=y)\n",
    "\n",
    "        # freeze the BERT layer - otherwise we will be training 100M+ parameters...\n",
    "        best_model.layers[2].trainable = False\n",
    "\n",
    "        best_model.compile(optimizer=Adam(learning_rate = hp.Choice('learning_rate', values=[0.001, 0.01]), clipnorm=hp.Choice('clip_norm', values= [1,3])), loss=\"binary_crossentropy\", metrics=[F1Score()])\n",
    "        return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f65b0e82ca0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f65b0e82ca0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "tuner = GridSearch(\n",
    "    hypermodel = MyHyperModel(),\n",
    "    objective = Objective('val_loss', 'min'),\n",
    "    max_trials = 20,\n",
    "    seed = SEED,\n",
    "    executions_per_trial = 1,\n",
    "    overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 7\n",
      "LSTM_units (Choice)\n",
      "{'default': 64, 'conditions': [], 'values': [64, 128], 'ordered': True}\n",
      "LSTM_recurrent_dropout (Choice)\n",
      "{'default': 0.0, 'conditions': [], 'values': [0.0, 0.3], 'ordered': True}\n",
      "rate_dropout (Choice)\n",
      "{'default': 0.6, 'conditions': [], 'values': [0.6, 0.7], 'ordered': True}\n",
      "dense_units (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n",
      "reg_value (Choice)\n",
      "{'default': 0.0, 'conditions': [], 'values': [0.0, 0.001], 'ordered': True}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.001, 'conditions': [], 'values': [0.001, 0.01], 'ordered': True}\n",
      "clip_norm (Choice)\n",
      "{'default': 1, 'conditions': [], 'values': [1, 3], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary(extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 Complete [00h 23m 43s]\n",
      "val_loss: 0.3974143862724304\n",
      "\n",
      "Best val_loss So Far: 0.3793085515499115\n",
      "Total elapsed time: 08h 41m 07s\n",
      "\n",
      "Search: Running Trial #13\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "64                |64                |LSTM_units\n",
      "0                 |0                 |LSTM_recurrent_dropout\n",
      "0.6               |0.6               |rate_dropout\n",
      "32                |32                |dense_units\n",
      "0.001             |0                 |reg_value\n",
      "0.001             |0.001             |learning_rate\n",
      "1                 |1                 |clip_norm\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - ETA: 0s - loss: 0.6180 - f1_score: 0.5634"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 181s 2s/step - loss: 0.6180 - f1_score: 0.5634 - val_loss: 0.5147 - val_f1_score: 0.7243\n",
      "Epoch 2/15\n",
      "78/78 [==============================] - 150s 2s/step - loss: 0.5264 - f1_score: 0.6912 - val_loss: 0.4717 - val_f1_score: 0.7499\n",
      "Epoch 3/15\n",
      "78/78 [==============================] - 149s 2s/step - loss: 0.4890 - f1_score: 0.7213 - val_loss: 0.4498 - val_f1_score: 0.7650\n",
      "Epoch 4/15\n",
      "78/78 [==============================] - 149s 2s/step - loss: 0.4673 - f1_score: 0.7272 - val_loss: 0.4310 - val_f1_score: 0.7626\n",
      "Epoch 5/15\n",
      "37/78 [=============>................] - ETA: 1:04 - loss: 0.4553 - f1_score: 0.7457"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=3,restore_best_weights=True, verbose=1)\n",
    "tuner.search(train, epochs=15, validation_data=validation, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search 10 best results\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on Best Trial\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training of best model\n",
    "es = EarlyStopping(monitor='val_f1_score', patience=5, restore_best_weights=True, verbose=1, mode=\"max\")\n",
    "history = best_model.fit(train, batch_size=BATCH_SIZE, epochs=60, callbacks=es, validation_data=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1-score plot\n",
    "plt.plot(history.history[\"f1_score\"], label='f1_score')\n",
    "plt.plot(history.history[\"val_f1_score\"], label='val_f1_score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim()\n",
    "plt.xticks(np.arange(len(history.history[\"val_f1_score\"])), np.arange(1, len(history.history[\"val_f1_score\"])+1))\n",
    "plt.legend(loc = 'lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss plot\n",
    "plt.plot(history.history[\"loss\"], label='loss')\n",
    "plt.plot(history.history[\"val_loss\"], label='val_loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim()\n",
    "plt.xticks(np.arange(len(history.history[\"loss\"])), np.arange(1, len(history.history[\"loss\"])+1))\n",
    "plt.xticks(np.arange(len(history.history[\"val_loss\"])), np.arange(1, len(history.history[\"val_loss\"])+1))\n",
    "plt.legend(loc = 'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_politics = best_model.predict(test_politics) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Classification Report\n",
    "print(classification_report(list(labelsTPolitics), pred_politics, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_religious = best_model.predict(test_religious) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Classification Report\n",
    "print(classification_report(list(labelsTReligious), pred_religious, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4417931,
     "sourceId": 7636529,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
